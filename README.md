# Data-Career-Portfolio

## Projects
### #1 [ETL] GCP Data Engineer Project
In this project, I designed and implemented an ETL data pipeline using Google Cloud Storage as Data Lake, Google BigQuery as Data Warehouse and Google Cloud Composer for runing Apache Airflow as Data Orchestrator.
This system is running on Google Cloud Platform.
* Technology used : Google Cloud Storage, Google BigQuery,  Airflow, Looker Studio.
* Dashboard : [Audible Sale Dashboard](https://lookerstudio.google.com/reporting/848e065d-171a-4f3f-8c79-06672c286890)

### #2 [ELT] Retail Data Engineer Project
In this project, I designed and implemented an ELT data pipeline, leveraging Google Cloud Storage as a robust Data Lake, Google BigQuery as a high-performance Data Warehouse, and Apache Airflow as the orchestrator. The entire system is seamlessly orchestrated locally through the Astro CLI.
* Technology used: Google Cloud Storage, Google BigQuery,  Airflow, Looker Studio, DBT Core, Docker
* Dashboard : [Retail Dashboard](https://lookerstudio.google.com/reporting/381987ec-9e6f-45ed-91b3-747c6375df3c)

### #3 Conizant Data Scientist Job Simulate
This virtual internship as Data Scientist, I..
- Completed a job simulation focused on AI for Cognizant’s Data Science team.
- Conducted exploratory data analysis using Python script and Python notebook  for one of Cognizant’s technology-led clients, Gala Groceries.
- Prepared a Python module that contains code to train a model and output the performance metrics for the Machine Learning engineering team.
- Communicated findings and analysis in the form of a PowerPoint slide to  present the results back to the business.


### #4 Simple LLM Chatbot
I developed LLM Chatbot using Langchain Framework and OpenAI as based LLM model. The chatbot can answer online course questions by understanding the context of the question and matching it with prepared prompts and answers.
* Technology used: Langchain Framework, OpenAI API, Faiss Vector Database, Streamlit
